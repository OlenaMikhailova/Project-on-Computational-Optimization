\documentclass[a4paper,12pt]{article}
\usepackage[ukrainian]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\geometry{left=2cm, right=2cm, top=2cm, bottom=2cm}

\title{Fundamental Definitions: Optimization Theory}
\author{Vladyslav Skrynyk, Olena Mikhailova}
\date{}

\begin{document}

\maketitle

\section{Fundamental Definitions}

\subsection{Convexity}  
A function $f: \mathbb{R}^n \to \mathbb{R}$ is called \textbf{convex} if for all $x, y \in \mathbb{R}^n$ and any $\lambda \in [0,1]$, the following holds:  
\[
    f(\lambda x + (1 - \lambda)y) \leq \lambda f(x) + (1 - \lambda) f(y). \tag{1}
\]  
\subsection{Strong Convexity}  
If a strict inequality holds in (1), the function is called \textbf{strongly convex}.  


\subsection{L-smoothness}  
A function \( f: \Omega \to \mathbb{R} \) is called \( L \)-smooth if its gradient is  
\( L \)-Lipschitz continuous, meaning that the following inequality holds:  
\[
\|\nabla f(x) - \nabla f(y)\|_2 \leq L \|x - y\|_2, \quad \forall x, y \in \Omega.
\]

*градієнт не змінюється надто критично*

\subsection{Descent Lemma}  
Let \( f: \Omega \to \mathbb{R} \) be an \( L \)-smooth function on a convex domain \( \Omega \).  
Then, the function \( f \) can be upper-bounded as follows:

\[
f(y) \leq f(x) + \langle \nabla f(x), y - x \rangle + \frac{L}{2} \|y - x\|_2^2, \quad \forall x, y \in \Omega. \quad (2)
\]
  
\textbf{Proof.} Express the increment \( f(y) - f(x) \) as an integral of the gradient along the line connecting \( x \) and \( y \),  
and then use the Lipschitz condition on the gradient \( \nabla f \) to estimate the increment:

\[
f(y) - f(x) = \int_0^1 \langle \nabla f(x + t \cdot (y - x)), y - x \rangle \, dt
\]
\[
= \left( \int_0^1 \langle \nabla f(x + t \cdot (y - x)) - \nabla f(x), y - x \rangle \, dt \right) + \langle \nabla f(x), y - x \rangle
\]
\[
\leq \left( \int_0^1 \|\nabla f(x + t \cdot (y - x)) - \nabla f(x)\|_2 \cdot \|y - x\|_2 \, dt \right) + \langle \nabla f(x), y - x \rangle
\]
\[
\leq \left( \int_0^1 t L \|y - x\|_2^2 \, dt \right) + \langle \nabla f(x), y - x \rangle
\]
\[
= \frac{L}{2} \|y - x\|_2^2 + \langle \nabla f(x), y - x \rangle.
\]
Rearranging the expressions, we obtain the statement of the theorem.


\textbf{Theorem (Gradient Descent Lemma, Additional).}  
Let \( f: \mathbb{R}^n \to \mathbb{R} \) be \( L \)-smooth.  
Then, for any \( 0 < \eta \leq \frac{1}{L} \), each step of gradient descent (1) guarantees:

\[
f(x_{t+1}) \leq f(x_t) - \frac{\eta}{2} \|\nabla f(x_t)\|_2^2.
\]


\subsection{Stepsize (Learning Rate)}  
The stepsize \( \alpha_k \) in an iterative method determines how far we move in the direction of the gradient:

\begin{equation}
    x_{k+1} = x_k - \alpha_k \nabla f(x_k).
\end{equation}

\subsection{Gradient Descent}  
The gradient descent method is defined by the recurrence relation:
\begin{equation}
    x_{k+1} = x_k - \alpha_k \nabla f(x_k),
\end{equation}
where \( \alpha_k \) is the step size. This is a first-order iterative optimization algorithm, where steps are taken proportional to the negative value of the gradient of the function at the current point to find a local (or global) minimum of the function.

\subsection{Linesearch}  
The method for determining the optimal step size \( \alpha_k \) by solving the following problem:

\begin{equation}
    \alpha_k = \arg\min_{\alpha > 0} f(x_k - \alpha \nabla f(x_k)).
\end{equation}

\subsubsection{Exact Line-Search}  
After selecting the direction (in gradient descent, this is the direction of the negative gradient), one can consider the following 1D optimization problem to determine the best step size:


\[
\eta_t = \arg\min_{\eta \geq 0} f(x_t - \eta \nabla f(x_t)).
\]

Often, solving this problem exactly is computationally difficult, so in practice, an approximate approach is usually used.


\subsubsection{Backtracking Line-Search}

The idea of the backtracking line-search method is generally to first try an aggressive (large) step size and then reduce it if it is too large.

The algorithm works as follows: we choose two parameters $\alpha \in (0, 0.5)$ and $\beta \in (0, 1)$. At iteration $t$:

\begin{enumerate}
    \item Initiate $\eta = 1$.
    \item \textbf{Check condition:} if 
    \[
    f(x_t - \eta \nabla f(x_t)) > f(x_t) - \alpha \eta \|\nabla f(x_t)\|_2^2,
    \]
    then update $\eta := \beta \times \eta$ and recheck condition.
    \item Otherwise:
    \[
    x_{t+1} = x_t - \eta \nabla f(x_t).
    \]
\end{enumerate}

In practice, values of $\alpha = 0.3$ and $\beta = 0.5$ are often used, which give good results.

\subsection{Metric Projection}
The metric projection of a point $x$ onto a convex set $C$ is defined as

\begin{equation}
    P_C(x) = \arg\min_{y \in C} \|x - y\|.
\end{equation}

\subsection{Convergence Rate}
The convergence rate of an optimization method characterizes how quickly the sequence $\{x_k\}$ approaches the optimal solution $x^*$. We consider:

\begin{itemize}
    \item Linear convergence: $\|x_k - x^*\| \leq C q^k$, where $q \in (0,1)$.
    \item Quadratic convergence: $\|x_{k+1} - x^*\| \leq C \|x_k - x^*\|^2$.
\end{itemize}

\subsubsection{Convergence Analysis}

Assume that the function $f$ is convex and differentiable, with its domain $\operatorname{dom}(f) = \mathbb{R}^n$, and the gradient $\nabla f$ is Lipschitz continuous with a constant $L > 0$:


\[
\|\nabla f(x) - \nabla f(y)\|_2 \leq L \|x - y\|_2, \quad \forall x, y \in \mathbb{R}^n.
\]

or, if $f$ twice differentiable:

\[
\nabla^2 f(x) \preceq L I.
\]

\textbf{Theorem:} Gradient descent with a fixed step size $t \leq \frac{1}{L}$ satisfies:

\[
f(x^{(k)}) - f^* \leq \frac{\|x^{(0)} - x^*\|_2^2}{2tk}.
\]

An analogous result holds for the backtracking method, if we replace $t$ with $\frac{\beta}{L}$.

Thus, gradient descent has a convergence rate of $O(1/k)$.


*Для того щоб отримати $f(x) - f(x^*) \leq \epsilon$ треба $O(1/\epsilon)$ ітерацій*


\end{document}
